{
  "id": 11141,
  "title": "Complete AI Safety Suite: Test 9 Guardrail Layers with Groq LLM",
  "slug": "complete-ai-safety-suite-test-9-guardrail-layers-with-groq-llm-11141",
  "description": "WHO'S IT FORAI developers, automation engineers, and teams building chatbots, AI agents, orworkflows that process user input. Perfect for those concerned about security,compliance, and content safety.WHAT IT DOESThis workflow demonstrates all 9 guardrail types available in n8n's Guardrailsnode through real-world test cases. It provides a comprehensive safety testingsuite that validates: * Keyword blocking for profanity and banned terms * Jailbreak detection to prevent prompt injection attacks * NSFW content filtering for inappropriate material * PII detection and sanitization for emails, phone numbers, and credit cards * Secret key detection to catch leaked API keys and tokens * Topical alignment to keep conversations on-topic * URL whitelisting to block malicious domains * Credential URL blocking to prevent URLs with embedded passwords * Custom regex patterns for organization-specific rules (employee IDs, order numbers) * Each test case flows through its corresponding guardrail node, with results formatted into clear pass/fail reports showing violations and sanitized text.HOW TO SET UP * Add your Groq API credentials (free tier works fine) * Import the workflow * Click \"Test workflow\" to run all 9 cases * Review the formatted results to understand each guardrail's behaviorREQUIREMENTS * n8n version 1.119.1 or later (for Guardrails node) * Groq API account (free tier sufficient) * Self-hosted instance (some guardrails use LLM-based detection)HOW TO CUSTOMIZE * Modify test cases in the \"Test Cases Data\" node to match your specific scenarios * Adjust threshold values (0.0-1.0) for AI-based guardrails to fine-tune sensitivity * Add or remove guardrails based on your security requirements * Integrate individual guardrail nodes into your production workflows * Use the sticky notes as reference documentation for implementationThis is a plug-and-play educational template that serves as both a testing suiteand implementation reference for building production-ready AI safety layers.",
  "metadescription": "Ensure content safety in your AI workflows with this n8n Guardrails test suite. Covers 9 guardrails, real test cases, and easy customization. Learn more!",
  "summary": "Ideal for AI developers and automation engineers focused on content safety, security, and compliance  \nShowcases all 9 n8n Guardrails, including keyword blocking, jailbreak detection, NSFW and PII filtering, secret key detection, topical alignment, URL whitelisting, credential URL blocking, and custom regex  \nRuns real-world test cases with clear pass/fail reports and automated sanitization  \nRequires n8n v1.119.1+, a Groq API account, and self-hosted deployment  \nEasily customizable: edit test cases, thresholds, and included guardrails  \nFunctions as a plug-and-play safety suite and hands-on template for building robust AI workflows",
  "date": "22 Nov 2025",
  "createdAtRaw": "2025-11-22T20:33:07.889+00:00",
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "nodeTypes": [
    "n8n-nodes-base.set",
    "n8n-nodes-base.splitOut",
    "n8n-nodes-base.stickyNote",
    "n8n-nodes-base.manualTrigger",
    "@n8n/n8n-nodes-langchain.guardrails",
    "@n8n/n8n-nodes-langchain.lmChatGroq"
  ],
  "author": {
    "name": "Muhammad Shaheer Awan",
    "username": "shaheer03",
    "avatar": "https://gravatar.com/avatar/6422749335803d7750620a19f2d5c39f276f306344f882113104d4c8d4053ad5?r=pg&d=retro&size=200",
    "verified": true
  },
  "popularity": 24,
  "visitors": 67,
  "inserters": 20,
  "templateUrl": "https://n8n.io/workflows/11141",
  "readme": "",
  "thumbnail": "https://supabase.amastuces.com/storage/v1/object/public/worklowscreenshot/11141-complete-ai-safety-suite--test-9-guardrail-layers-with-groq-llm.webp",
  "complexityLevel": "advanced",
  "templateData": null,
  "price": 0,
  "referalUrl": null
}